{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/GraphST/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn import metrics\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from GraphST import GraphST\n",
    "from GraphST.utils import clustering\n",
    "from st_loading_utils import load_mPFC, load_mHypothalamus, load_her2_tumor, load_mMAMP, load_spacelhBC, load_DLPFC, load_BC, load_mVC\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# Run device, by default, the package is implemented on 'cpu'. We recommend using GPU.\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "iters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mouse hoppocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (30.0, 10.0)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 26\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to train ST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [19:37<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished for ST data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]:                    __           __ \n",
      "   ____ ___  _____/ /_  _______/ /_\n",
      "  / __ `__ \\/ ___/ / / / / ___/ __/\n",
      " / / / / / / /__/ / /_/ (__  ) /_  \n",
      "/_/ /_/ /_/\\___/_/\\__,_/____/\\__/   version 5.4.10\n",
      "Type 'citation(\"mclust\")' for citing this R package in publications.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "AAAAAAAGTCCCAA     6\n",
      "AAAAAACATCTTTC    14\n",
      "AAAAAACTTCTACT     4\n",
      "AAAAAATTTACAAC     4\n",
      "AAAAACACGGTGGT     2\n",
      "                  ..\n",
      "TTTTTTTCTGACGG    13\n",
      "TTTTTTTCTGCAGT     4\n",
      "TTTTTTTCTGCCAT    11\n",
      "TTTTTTTTCGCTTA     2\n",
      "TTTTTTTTTCGGTG    11\n",
      "Name: domain, Length: 41770, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'original_clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/GraphST/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/GraphST/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/GraphST/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_clusters'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# ad.uns['runtime'] = time_end - time_start\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# run_times.append(time_end - time_start)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# ad.X = csr_matrix(ad.X)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# ad.write_h5ad(os.path.join(save_dir_gt, dataset, 'iter'+str(iter)+'.h5ad'))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# calculate metric ARI\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(ad\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(ad\u001b[39m.\u001b[39;49mobs[\u001b[39m'\u001b[39;49m\u001b[39moriginal_clusters\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m ARI \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39madjusted_rand_score(ad\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m], ad\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39moriginal_clusters\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# ad.uns['ARI'] = ARI\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcclab/home/yunfei/spatial_benchmarking/BenchmarkST/GraphST/run_GraphST/run_GraphST.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# print('Dataset:', dataset)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GraphST/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/GraphST/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_clusters'"
     ]
    }
   ],
   "source": [
    "\"\"\"spacel hBC\"\"\"\n",
    "# the number of clusters\n",
    "n_clusters = 14\n",
    "\n",
    "dataset = 'sshippo.h5ad'\n",
    "\n",
    "dir_ = '/home/yunfei/spatial_benchmarking/benchmarking_data/mouse_hyppocampus_slideseqv2'\n",
    "ad = sc.read_h5ad(os.path.join(dir_, dataset))\n",
    "aris = []\n",
    "run_times = []\n",
    "for iter in range(1):\n",
    "    # define model\n",
    "    time_start = time.time()\n",
    "    model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "    # train model\n",
    "    ad = model.train()\n",
    "\n",
    "    # print(ad)\n",
    "\n",
    "    # set radius to specify the number of neighbors considered during refinement\n",
    "    radius = 30\n",
    "\n",
    "    tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "    # clustering\n",
    "    if tool == 'mclust':\n",
    "        clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "    elif tool in ['leiden', 'louvain']:\n",
    "        clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "    time_end = time.time()      \n",
    "\n",
    "    # filter out NA nodes\n",
    "    ad = ad[~pd.isnull(ad.obs['cluster'])]\n",
    "    # ad.uns['runtime'] = time_end - time_start\n",
    "    # run_times.append(time_end - time_start)\n",
    "    # ad.X = csr_matrix(ad.X)\n",
    "\n",
    "    # if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "    #     os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "    # ad.write_h5ad(os.path.join(save_dir_gt, dataset, 'iter'+str(iter)+'.h5ad'))\n",
    "    # calculate metric ARI\n",
    "    print(ad.obs['domain'])\n",
    "    # print(ad.obs['original_clusters'])\n",
    "    ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['cluster'])\n",
    "    # ad.uns['ARI'] = ARI\n",
    "\n",
    "    # print('Dataset:', dataset)\n",
    "    print('ARI:', ARI)\n",
    "    aris.append(ARI)\n",
    "\n",
    "    sc.pl.spatial(ad,\n",
    "            color=[\"mclust\", \"cluster\"],\n",
    "            title=[\"GraphST\", \"Ground Truth\"],\n",
    "            show=False, spot_size=20)\n",
    "    plt.savefig(os.path.join(\"/home/yunfei/spatial_benchmarking/BenchmarkST/analysis1110/clustering/mousehippo\", \"hippocampus_GraphST.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['cluster'])\n",
    "# ad.uns['ARI'] = ARI\n",
    "\n",
    "# print('Dataset:', dataset)\n",
    "print('ARI:', ARI)\n",
    "aris.append(ARI)\n",
    "\n",
    "sc.pl.spatial(ad,\n",
    "        color=[\"mclust\", \"cluster\"],\n",
    "        title=[\"GraphST\", \"Ground Truth\"],\n",
    "        show=False, spot_size=20)\n",
    "plt.savefig(os.path.join(\"/home/yunfei/spatial_benchmarking/BenchmarkST/analysis1110/clustering/mousehippo\", \"hippocampus_GraphST.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outdated spacel hbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to train ST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 56.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished for ST data!\n",
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "AAACAAGTATCTCCCA-1    1\n",
      "AAACACCAATAACTGC-1    2\n",
      "AAACAGAGCGACTCCT-1    1\n",
      "AAACAGGGTCTATATT-1    1\n",
      "AAACAGTGTTCCTGGG-1    2\n",
      "                     ..\n",
      "TTGTTGTGTGTCAAGA-1    1\n",
      "TTGTTTCACATCCAGG-1    2\n",
      "TTGTTTCATTAGTCTA-1    2\n",
      "TTGTTTCCATACAACT-1    3\n",
      "TTGTTTGTGTAAATTC-1    1\n",
      "Name: domain, Length: 3798, dtype: object\n",
      "AAACAAGTATCTCCCA-1    Intermediate\n",
      "AAACACCAATAACTGC-1           Tumor\n",
      "AAACAGAGCGACTCCT-1    Intermediate\n",
      "AAACAGGGTCTATATT-1          Immune\n",
      "AAACAGTGTTCCTGGG-1           Tumor\n",
      "                          ...     \n",
      "TTGTTGTGTGTCAAGA-1    Intermediate\n",
      "TTGTTTCACATCCAGG-1    Intermediate\n",
      "TTGTTTCATTAGTCTA-1           Tumor\n",
      "TTGTTTCCATACAACT-1    Intermediate\n",
      "TTGTTTGTGTAAATTC-1           Tumor\n",
      "Name: original_clusters, Length: 3798, dtype: object\n",
      "ARI: -0.011941063017150786\n",
      "Begin to train ST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 55.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished for ST data!\n",
      "fitting ...\n",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# clustering\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m tool \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmclust\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     clustering(ad, n_clusters, radius\u001b[39m=\u001b[39;49mradius, method\u001b[39m=\u001b[39;49mtool, refinement\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m# For DLPFC dataset, we use optional refinement step.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39melif\u001b[39;00m tool \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mleiden\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlouvain\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     43\u001b[0m     clustering(ad, n_clusters, radius\u001b[39m=\u001b[39mradius, method\u001b[39m=\u001b[39mtool, start\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, increment\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, refinement\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/GraphST-1.1.1-py3.8.egg/GraphST/utils.py:81\u001b[0m, in \u001b[0;36mclustering\u001b[0;34m(adata, n_clusters, radius, key, method, start, end, increment, refinement)\u001b[0m\n\u001b[1;32m     78\u001b[0m    adata\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mlouvain\u001b[39m\u001b[39m'\u001b[39m] \n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m refinement:  \n\u001b[0;32m---> 81\u001b[0m    new_type \u001b[39m=\u001b[39m refine_label(adata, radius, key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdomain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m    adata\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_type\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/GraphST-1.1.1-py3.8.egg/GraphST/utils.py:101\u001b[0m, in \u001b[0;36mrefine_label\u001b[0;34m(adata, radius, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_neigh\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    100\u001b[0m         neigh_type\u001b[39m.\u001b[39mappend(old_type[index[j]])\n\u001b[0;32m--> 101\u001b[0m     max_type \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(neigh_type, key\u001b[39m=\u001b[39;49mneigh_type\u001b[39m.\u001b[39;49mcount)\n\u001b[1;32m    102\u001b[0m     new_type\u001b[39m.\u001b[39mappend(max_type)\n\u001b[1;32m    104\u001b[0m new_type \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(new_type)]    \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"spacel hBC\"\"\"\n",
    "# the number of clusters\n",
    "# setting_combinations = [[10, 'human_bc_spatial_1142243F'],\n",
    "#                         [10, 'human_bc_spatial_1160920F'], \n",
    "#                         [10, 'human_bc_spatial_CID4290'], \n",
    "#                         [10, 'human_bc_spatial_CID4465'], \n",
    "#                         [10, 'human_bc_spatial_CID4535'], \n",
    "#                         [10, 'human_bc_spatial_CID44971'], \n",
    "#                         [10, 'human_bc_spatial_Parent_Visium_Human_BreastCancer'], \n",
    "#                         [10, 'human_bc_spatial_V1_Breast_Cancer_Block_A_Section_1'],\n",
    "#                         [10, 'human_bc_spatial_V1_Breast_Cancer_Block_A_Section_2'],\n",
    "#                         [10, 'human_bc_spatial_V1_Human_Invasive_Ductal_Carcinoma'],\n",
    "#                         [10, 'human_bc_spatial_Visium_FFPE_Human_Breast_Cancer']]\n",
    "# for setting_combi in setting_combinations:\n",
    "n_clusters = 3\n",
    "\n",
    "dataset = 'human_bc_spatial_V1_Breast_Cancer_Block_A_Section_1'\n",
    "\n",
    "dir_ = '/home/yunfei/spatial_benchmarking/benchmarking_data/visium_human_breast_cancer'\n",
    "ad = load_spacelhBC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "aris = []\n",
    "run_times = []\n",
    "for iter in range(iters):\n",
    "    # define model\n",
    "    time_start = time.time()\n",
    "    model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "    # train model\n",
    "    ad = model.train()\n",
    "\n",
    "    # print(ad)\n",
    "\n",
    "    # set radius to specify the number of neighbors considered during refinement\n",
    "    radius = 400\n",
    "\n",
    "    tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "    # clustering\n",
    "    if tool == 'mclust':\n",
    "        clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "    elif tool in ['leiden', 'louvain']:\n",
    "        clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "    time_end = time.time()      \n",
    "\n",
    "    # filter out NA nodes\n",
    "    ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "    # ad.uns['runtime'] = time_end - time_start\n",
    "    # run_times.append(time_end - time_start)\n",
    "    # ad.X = csr_matrix(ad.X)\n",
    "\n",
    "    # if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "    #     os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "    # ad.write_h5ad(os.path.join(save_dir_gt, dataset, 'iter'+str(iter)+'.h5ad'))\n",
    "    # calculate metric ARI\n",
    "    print(ad.obs['domain'])\n",
    "    print(ad.obs['original_clusters'])\n",
    "    ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "    # ad.uns['ARI'] = ARI\n",
    "\n",
    "    # print('Dataset:', dataset)\n",
    "    print('ARI:', ARI)\n",
    "    aris.append(ARI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
